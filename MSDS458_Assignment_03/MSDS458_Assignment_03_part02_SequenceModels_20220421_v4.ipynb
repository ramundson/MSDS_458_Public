{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJ-2a8LRro5"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6cApW345ukg"
      },
      "source": [
        "## MSDS458 Research Assignment 3 - Part 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hblbilyx5ukg"
      },
      "source": [
        "## Analyze AG_NEWS_SUBSET Data <br>\n",
        "\n",
        "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.<br> \n",
        "\n",
        "For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html<br> \n",
        "\n",
        "\n",
        "The AG's news topic classification dataset is constructed by choosing 4 largest classes (**World**, **Sports**, **Business**, and **Sci/Tech**) from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.<br>\n",
        "\n",
        "Homepage: https://arxiv.org/abs/1509.01626<br>\n",
        "\n",
        "Source code: tfds.text.AGNewsSubset\n",
        "\n",
        "Versions:\n",
        "\n",
        "1.0.0 (default): No release notes.\n",
        "Download size: 11.24 MiB\n",
        "\n",
        "Dataset size: 35.79 MiB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95DGbFzR5uki"
      },
      "source": [
        "## References\n",
        "1. Deep Learning with Python, Francois Chollet (https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/)\n",
        " * Chapter 10: Deep learning for time series\n",
        " * Chapter 11: Deep learning for text\n",
        "2. Deep Learning A Visual Approach, Andrew Glassner (https://learning.oreilly.com/library/view/deep-learning/9781098129019/)\n",
        " * Chapter 19: Recurrent Neural Networks\n",
        " * Chapter 20: Attention and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8kwmgNRro7"
      },
      "source": [
        "## Processing words as a sequence: The sequence model approach\n",
        "\n",
        "To implement a sequence model, you’d start by representing your input samples as sequences of integer indices (one integer standing for one word). Then, you’d map each integer to a vector to obtain vector sequences. Finally, you’d feed these sequences of vectors into a stack of layers that could cross-correlate features from adjacent vectors, such as a 1D convnet, a RNN, or a Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AQ7tuV5ukj"
      },
      "source": [
        "For some time around 2016–2017, bidirectional RNNs (in particular, `bidirectional LSTMs`) were considered to be the state of the art for sequence modeling. However, nowadays sequence modeling is almost universally done with `Transformers`. \n",
        "\n",
        "F. Chollet: \"One-dimensional convnets were never very popular in NLP, even though, a residual stack of depthwise-separable 1D convolutions can often achieve comparable performance to a bidirectional LSTM, at a greatly reduced computational cost.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydgzc1l15ukl"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9d9VZa_T5ukm"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt8VbLK5ukp"
      },
      "source": [
        "## Verify TensorFlow version and Keras version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kujC9adr5ukq",
        "outputId": "75244880-7418-44a3-d748-0d0029628736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook requires TensorFlow 2.0 or above\n",
            "TensorFlow version:  2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHdPTZRp5ukr",
        "outputId": "1f55a1e9-a77d-46e8-cba8-a380dffe2de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras version: \", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Gn6wYG5uks"
      },
      "source": [
        "## Mount Google Drive to Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8jHzLMMB5ukt"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvqFLia1Rro9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsypDzDARro-",
        "outputId": "7734c74f-e5a4-4f03-f9de-94d3557f7a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0426 12:44:59.300033 140470340908928 download_and_prepare.py:200] Running download_and_prepare for dataset(s):\n",
            "ag_news_subset\n",
            "2022-04-26 12:44:59.482614: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "I0426 12:44:59.894230 140470340908928 dataset_info.py:434] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "I0426 12:45:00.599655 140470340908928 dataset_info.py:361] Load dataset info from /tmp/tmpmzoyjg6otfds\n",
            "I0426 12:45:00.601661 140470340908928 download_and_prepare.py:138] download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "I0426 12:45:00.602037 140470340908928 dataset_builder.py:357] Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset ag_news_subset/1.0.0 (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0426 12:45:01.005621 140470340908928 download_manager.py:476] Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.52a5345a90a34db6810a5d1aeb7d468e...\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:25<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:25<04:11, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:25<03:46, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:25<03:21, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:25<02:56, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:25<02:30, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:25<02:05, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:25<01:40, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:25<01:15, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:25<00:50, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:25<00:25, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:25<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:25<00:00, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 25.24s/ url]\n",
            "Dl Size...: 100% 11/11 [00:25<00:00, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 25.24s/ url]\n",
            "Dl Size...: 100% 11/11 [00:25<00:00, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:25<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 25.24s/ url]\n",
            "Dl Size...: 100% 11/11 [00:25<00:00, 25.15s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:25<00:00, 25.55s/ file]\u001b[A\u001b[A\n",
            "Extraction completed...: 100% 1/1 [00:25<00:00, 25.55s/ file]\n",
            "\n",
            "Dl Size...: 100% 11/11 [00:25<00:00,  2.32s/ MiB]\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 25.55s/ url]\n",
            "I0426 12:45:26.553095 140470340908928 dataset_builder.py:970] Generating split train\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteRPGLMO/ag_news_subset-train.tfrecord\n",
            " 83% 99397/120000 [00:00<00:00, 384620.33 examples/s]I0426 12:45:47.224866 140470340908928 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteRPGLMO/ag_news_subset-train.tfrecord. Shard lengths: [120000]\n",
            "I0426 12:45:47.239974 140470340908928 dataset_builder.py:970] Generating split test\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteRPGLMO/ag_news_subset-test.tfrecord\n",
            "  0% 0/7600 [00:00<?, ? examples/s]I0426 12:45:48.534570 140470340908928 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteRPGLMO/ag_news_subset-test.tfrecord. Shard lengths: [7600]\n",
            "I0426 12:45:48.536395 140470340908928 dataset_builder.py:412] Skipping computing stats for mode ComputeStatsMode.SKIP.\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "\u001b[1mname: \"ag_news_subset\"\n",
            "description: \"AG is a collection of more than 1 million news articles.\\nNews articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\\nComeToMyHead is an academic news search engine which has been running since July, 2004.\\nThe dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\\ninformation retrieval (ranking, search, etc), xml, data compression, data streaming,\\nand any other non-commercial activity.\\nFor more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\\n\\nThe AG\\'s news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\\nIt is used as a text classification benchmark in the following paper:\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\\n\\nThe AG\\'s news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\\nEach class contains 30,000 training samples and 1,900 testing samples.\\nThe total number of training samples is 120,000 and testing 7,600.\"\n",
            "citation: \"@misc{zhang2015characterlevel,\\n    title={Character-level Convolutional Networks for Text Classification},\\n    author={Xiang Zhang and Junbo Zhao and Yann LeCun},\\n    year={2015},\\n    eprint={1509.01626},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\"\n",
            "location {\n",
            "  urls: \"https://arxiv.org/abs/1509.01626\"\n",
            "}\n",
            "splits {\n",
            "  name: \"test\"\n",
            "  shard_lengths: 7600\n",
            "  num_bytes: 2226751\n",
            "}\n",
            "splits {\n",
            "  name: \"train\"\n",
            "  shard_lengths: 120000\n",
            "  num_bytes: 35301386\n",
            "}\n",
            "supervised_keys {\n",
            "  input: \"description\"\n",
            "  output: \"label\"\n",
            "}\n",
            "version: \"1.0.0\"\n",
            "download_size: 11784327\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "dataset,info=\\\n",
        "tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test'],batch_size = 32\n",
        "          , as_supervised=True)\n",
        "\n",
        "train_ds, val_ds, test_ds = dataset\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7Q6zlFRro_"
      },
      "source": [
        "## Preparing Integer Sequence Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AfTnCGIERrpA"
      },
      "outputs": [],
      "source": [
        "max_length = 150\n",
        "max_tokens = 1000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBL0CkaB5ukv"
      },
      "source": [
        "## Bi-directional RNN\n",
        "\n",
        "When translating in real-time, it would help to have access to worlds towards the end of a sentence, say, as well as earlier words in the sentence. One way to use the later words in the sentence is to feed the words into our RNN backward. So if we create two independent RNNs, we can feed one the words in their forward, or natural order, and the second gets their words in the revser order. This is the idea behind `Bi-directional RNNS`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuP7exeZ5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/BidirectionalRNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCNo3kUl5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/Bidirectional2RNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN2wjSjdRrpB"
      },
      "source": [
        "## Sequence Model Built on One-Hot Encoded Vector Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq6dB-zWRrpB",
        "outputId": "07bf29a3-0b34-4d7a-c198-429cc5a336ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 1000)        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               264448    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264,708\n",
            "Trainable params: 264,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64NWZQc5ukx"
      },
      "source": [
        "## One input is a sequence of integers.\n",
        "\n",
        "1. In order to keep a manageable input size, we’ll truncate the inputs after the first 150 words. This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 150 words.\n",
        "\n",
        "2. Encode the integers into binary 1,000-dimensional vectors.\n",
        "\n",
        "3. Add a bidirectional LSTM.\n",
        "\n",
        "4. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognTeJM6RrpC"
      },
      "source": [
        "## Training Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCbHrrsRrpC",
        "outputId": "ec4e9d78-5423-4634-c339-fff4d4c5fc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 62s 15ms/step - loss: 0.5894 - accuracy: 0.7884 - val_loss: 0.4217 - val_accuracy: 0.8572\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 53s 15ms/step - loss: 0.4418 - accuracy: 0.8497 - val_loss: 0.4118 - val_accuracy: 0.8567\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.4256 - accuracy: 0.8557 - val_loss: 0.4035 - val_accuracy: 0.8608\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 53s 15ms/step - loss: 0.4166 - accuracy: 0.8580 - val_loss: 0.3980 - val_accuracy: 0.8625\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.4085 - accuracy: 0.8605 - val_loss: 0.3964 - val_accuracy: 0.8667\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 53s 15ms/step - loss: 0.4042 - accuracy: 0.8627 - val_loss: 0.3961 - val_accuracy: 0.8633\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3972 - accuracy: 0.8653 - val_loss: 0.3958 - val_accuracy: 0.8638\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3931 - accuracy: 0.8673 - val_loss: 0.3940 - val_accuracy: 0.8673\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3899 - accuracy: 0.8679 - val_loss: 0.3949 - val_accuracy: 0.8660\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3854 - accuracy: 0.8698 - val_loss: 0.3922 - val_accuracy: 0.8657\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3800 - accuracy: 0.8717 - val_loss: 0.4024 - val_accuracy: 0.8632\n",
            "238/238 [==============================] - 3s 8ms/step - loss: 0.4115 - accuracy: 0.8588\n",
            "Test acc: 0.859\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTprEi3bRrpD"
      },
      "source": [
        "## Understanding word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmHdhUnM5ukz"
      },
      "source": [
        "When you encode something via `one-hot encoding`, you’re making a feature-engineering decision. You’re injecting into your model a fundamental assumption about the structure of your feature space. That assumption is that the different tokens you’re encoding are all independent from each other: indeed, one-hot vectors are all orthogonal to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "webaWkZJ5ukz"
      },
      "source": [
        "However, in a reasonable word vector space, you would expect synonyms to be embedded into similar word vectors, and in general, you would expect the geometric distance  between any two word vectors to relate to the “semantic distance” between the associated words.\n",
        "\n",
        "Words that mean different things should lie far away from each other, whereas related words should be closer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-W1sFgg5ukz"
      },
      "source": [
        "`Word embeddings` are vector representations of words that achieve exactly this: they map human language into a structured geometric space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egzHasW5ukz"
      },
      "source": [
        "Whereas the vectors obtained through `one-hot encoding` are *binary*, *sparse*, and *very high-dimensional* (the same dimensionality as the number of words in the vocabulary), `word embeddings` are *low-dimensional floating-point vectors* (that is, `dense vectors`, as opposed to `sparse vectors`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHU4tS3b5uk0"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/EmbeddingsSparse.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im1j5PRE5uk0"
      },
      "source": [
        "## Two ways to obtain word embeddings\n",
        "\n",
        "1. `Learn word embeddings jointly with the main task you care about` (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
        "2. Load into your model word embeddings that were precomputed using a different machine learning task than the one you’re trying to solve. These are called `pretrained word embeddings`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNyH_fhRrpD"
      },
      "source": [
        "## Learning Word Embeddings With The Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYLfdJY5uk0"
      },
      "source": [
        "What makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal-document classification model, because the importance of certain semantic relationships varies from task to task.\n",
        "\n",
        "It’s thus reasonable to learn a new embedding space with every new task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j69C96c65uk1"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Embedding</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrVeqKcsRrpE"
      },
      "source": [
        "## Instantiating An Embedding Layer\n",
        "\n",
        "The Embedding layer takes at least two arguments: the number of possible tokens and the dimensionality of the embeddings (here, 256)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WLTjxbMnRrpE"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWx26f9C5uk2"
      },
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mox7FQp5uk2"
      },
      "source": [
        "The Embedding layer takes as input a rank-2 tensor of integers, of shape `(batch_size, sequence_length)`, where each entry is a sequence of integers. The layer then returns a 3D floating-point tensor of shape `(batch_size, sequence_length, embedding_ dimensionality)`.Again, embedding_ dimensionality is 256 above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSfWWNO6RrpE"
      },
      "source": [
        "## Model Leveraging Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLuGKCM35uk2"
      },
      "source": [
        "One input is a sequence of integers.\n",
        "1. Encode the integers into binary 20,000-dimensional vectors.\n",
        "2. Add a bidirectional LSTM.\n",
        "3. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JFON-CRrpF",
        "outputId": "85f85ce4-5ca0-4002-f4d8-efa4fb5386c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 56s 15ms/step - loss: 0.5100 - accuracy: 0.8238 - val_loss: 0.4088 - val_accuracy: 0.8572\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.4327 - accuracy: 0.8518 - val_loss: 0.3935 - val_accuracy: 0.8610\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.4148 - accuracy: 0.8573 - val_loss: 0.3865 - val_accuracy: 0.8638\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.4030 - accuracy: 0.8607 - val_loss: 0.3839 - val_accuracy: 0.8638\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 53s 15ms/step - loss: 0.3951 - accuracy: 0.8635 - val_loss: 0.3855 - val_accuracy: 0.8638\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3865 - accuracy: 0.8665 - val_loss: 0.3871 - val_accuracy: 0.8657\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3808 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8643\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3743 - accuracy: 0.8715 - val_loss: 0.3928 - val_accuracy: 0.8642\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3685 - accuracy: 0.8734 - val_loss: 0.3885 - val_accuracy: 0.8625\n",
            "238/238 [==============================] - 2s 7ms/step - loss: 0.3959 - accuracy: 0.8578\n",
            "Test acc: 0.858\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHF_wA3x5uk3"
      },
      "source": [
        "It trains much faster than the one-hot model (since the LSTM only has to process 256-dimensional vectors instead of 1,000-dimensional), and its test accuracy is comparable (86%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0gOTdNnRrpF"
      },
      "source": [
        "## Understanding Padding and Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOudeXoa5uk4"
      },
      "source": [
        "One thing that’s slightly hurting model performance here is that our input sequences are full of zeros. This comes from our use of the `output_sequence_length=max_ length` option in TextVectorization (with `max_length equal` to 150): sentences longer than 150 tokens are truncated to a length of 150 tokens, and sentences shorter than 150 tokens are padded with zeros at the end so that they can be concatenated together with other sequences to form contiguous batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM95tdc65uk4"
      },
      "source": [
        "The RNN that looks at the tokens in their natural order will spend its last iterations seeing only vectors that encode padding—possibly for several hundreds of iterations if the original sentence was short. The information stored in the internal state of the RNN will gradually fade out as it gets exposed to these meaningless inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U93_Szgn5uk4"
      },
      "source": [
        "We need some way to tell the RNN that it should skip these iterations. There’s an API for that: `masking`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1SxQSW85uk4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Masking</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGe0pvoxRrpF"
      },
      "source": [
        "## Model Leveraging Embedding Layer With Masking Enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6YKNrDRrpF",
        "outputId": "623c87a1-da2c-4065-d746-a9969bdccf67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 58s 14ms/step - loss: 0.4853 - accuracy: 0.8296 - val_loss: 0.4029 - val_accuracy: 0.8607\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.4162 - accuracy: 0.8550 - val_loss: 0.3873 - val_accuracy: 0.8660\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3988 - accuracy: 0.8600 - val_loss: 0.3817 - val_accuracy: 0.8680\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.3882 - accuracy: 0.8650 - val_loss: 0.3802 - val_accuracy: 0.8665\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.3778 - accuracy: 0.8683 - val_loss: 0.3790 - val_accuracy: 0.8668\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3692 - accuracy: 0.8716 - val_loss: 0.3771 - val_accuracy: 0.8683\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3610 - accuracy: 0.8748 - val_loss: 0.3807 - val_accuracy: 0.8658\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.3537 - accuracy: 0.8776 - val_loss: 0.3854 - val_accuracy: 0.8657\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.3459 - accuracy: 0.8800 - val_loss: 0.3841 - val_accuracy: 0.8662\n",
            "238/238 [==============================] - 3s 6ms/step - loss: 0.4018 - accuracy: 0.8617\n",
            "Test acc: 0.862\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDRunHYSRrpG"
      },
      "source": [
        "## Using Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivO55Vo15uk6"
      },
      "source": [
        "The rationale behind using `pretrained word embedding`s in natural language processing is much the same as for using pretrained convnets in image classification: *you don’t have enough data available to learn truly powerful features on your own*, but you expect that the features you need are fairly generic—that is, common visual features or semantic features. In this case, it makes sense to reuse features learned on a different problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllLQfXb5uk6"
      },
      "source": [
        "The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s, but it only started to take off in research and industry applications after the release of one of the most famous and successful word-embedding schemes: the `Word2Vec` algorithm (https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. `Word2Vec` dimensions capture specific semantic properties, such as gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqJwrpr5uk6"
      },
      "source": [
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. `Word2vec` is one of them. Another popular one is called `Global Vectors for Word Representatio`n (GloVe, https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of English tokens, obtained from Wikipedia data and Common Crawl data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNrxDE65uk6"
      },
      "source": [
        "First, let’s download the GloVe word embeddings precomputed on the 2014 English Wikipedia dataset. It’s an 822 MB zip file containing 100-dimensional embedding vectors for 400,000 words (or non-word tokens)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6O5iXN5uk7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>GloVe: Global Vectors for Word Representation</b><br>\n",
        "https://nlp.stanford.edu/projects/glove/</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EjBZq6cRrpG",
        "outputId": "0a909db7-a890-4179-c7e3-90b28e808805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 13:12:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-04-26 13:12:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-26 13:12:05--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.97MB/s    in 2m 42s  \n",
            "\n",
            "2022-04-26 13:14:47 (5.08 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ifl-sJRrpH"
      },
      "source": [
        "## Parsing The GloVe Word-Embeddings File\n",
        "\n",
        "First line of `glove.6B.100d.txt`:\n",
        "\n",
        "`the -0.038194 -0.24487 0.72812 ...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPo9aWdbRrpH",
        "outputId": "bc7d6d30-2df4-484f-eaf7-493a63561ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # np.dtype('f') returns dtype('float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evKxdRndRrpH"
      },
      "source": [
        "## Preparing The GloVe Word-Embeddings Matrix\n",
        "\n",
        "Next, let’s build an embedding matrix that you can load into an Embedding layer. It must be a matrix of shape `(max_words, embedding_dim)`, where each entry *i* contains the `embedding_dim`-dimensional vector for the word of index *i* in the reference word index (built during tokenization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jSCD2_KcRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "# Retrieve the vocabulary indexed by our previous TextVectorization layer.\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "# Use it to create a mapping from words to their index in the vocabulary.\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "# Fill entry i in the matrix with the word vector for index i.\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:  # Words not found in the embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZE2xRs4QRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsE9u-g5uk9"
      },
      "source": [
        "We’re now ready to train a new model—identical to our previous model, but leveraging the `100-dimensional` pretrained GloVe embeddings instead of `256-dimensional` learned embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aXYeW8o5uk9"
      },
      "source": [
        "## One possible alternative to GloVE: ELMo (Embedding from Language Models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOckichs5uk9"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoArchitecture.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeEWdhm_5uk9"
      },
      "source": [
        "### \"Although the word is written in the identical way in each sentence, ELMo is able to identify the correct embedding based on the word’s context.\"\n",
        "\n",
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoComparison.png?raw=1\">\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=cPMCaxrZwp7t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOA_ss3iRrpJ"
      },
      "source": [
        "## Model Leveraging Pretrained (GloVe) Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI8Tj4g1RrpJ",
        "outputId": "f64c86ac-3a76-41bd-9599-507d0b0ca99c",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 100)         100000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,308\n",
            "Trainable params: 34,308\n",
            "Non-trainable params: 100,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 53s 13ms/step - loss: 0.5065 - accuracy: 0.8185 - val_loss: 0.4182 - val_accuracy: 0.8503\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.4316 - accuracy: 0.8457 - val_loss: 0.3949 - val_accuracy: 0.8577\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.4101 - accuracy: 0.8532 - val_loss: 0.3797 - val_accuracy: 0.8623\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3981 - accuracy: 0.8578 - val_loss: 0.3716 - val_accuracy: 0.8660\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3879 - accuracy: 0.8614 - val_loss: 0.3699 - val_accuracy: 0.8637\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3789 - accuracy: 0.8644 - val_loss: 0.3671 - val_accuracy: 0.8662\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3723 - accuracy: 0.8671 - val_loss: 0.3663 - val_accuracy: 0.8677\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3661 - accuracy: 0.8696 - val_loss: 0.3634 - val_accuracy: 0.8682\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3610 - accuracy: 0.8716 - val_loss: 0.3621 - val_accuracy: 0.8685\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3558 - accuracy: 0.8723 - val_loss: 0.3628 - val_accuracy: 0.8693\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3518 - accuracy: 0.8746 - val_loss: 0.3605 - val_accuracy: 0.8710\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3467 - accuracy: 0.8772 - val_loss: 0.3682 - val_accuracy: 0.8710\n",
            "Epoch 13/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3432 - accuracy: 0.8772 - val_loss: 0.3668 - val_accuracy: 0.8677\n",
            "Epoch 14/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.3400 - accuracy: 0.8799 - val_loss: 0.3709 - val_accuracy: 0.8643\n",
            "238/238 [==============================] - 3s 5ms/step - loss: 0.3795 - accuracy: 0.8655\n",
            "Test acc: 0.866\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5fqFXCOO5uk-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MSDS458_Assignment_03_part02_SequenceModels_20220421_DEV_v4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}